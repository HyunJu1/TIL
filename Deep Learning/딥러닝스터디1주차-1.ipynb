{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch\n",
    "    Define-by-Run\n",
    "### Pytorch Packages\n",
    "    torch\n",
    "    torch.autograd\n",
    "    torch.nn\n",
    "    torch.optim\n",
    "    torch.multiprocessing\n",
    "    torch.utils\n",
    "    torch.legact\n",
    "### Pytorch Tensor Basic Usage\n",
    "    Create Tensor\n",
    "    Indexing, Joining, Slicing\n",
    "    Initialization\n",
    "    Math Operations\n",
    "### 1. Create Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9043, 0.3494, 0.0692],\n",
       "        [0.9931, 0.1283, 0.7123]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# torch.rand(size)\n",
    "# 0~1 사이의 연속균등분포에서 값을 뽑아 5x3 텐서를 생성합니다. ~U(0,1)\n",
    "x = torch.rand(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8794, 1.3950, 2.4325, 1.7419, 1.5864],\n",
       "        [1.1483, 0.4369, 1.2853, 1.1647, 0.9593],\n",
       "        [1.5752, 0.9025, 1.6632, 1.2300, 1.2428]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.randn(size)\n",
    "# randn의 경우 평균은 0, 표준편차는 1인 정규분포에서 값을 가져옵니다. ~z(0,1)\n",
    "x1=torch.rand(3,4)\n",
    "x2=torch.rand(4,5)\n",
    "torch.mm(x1,x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3, 2, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.randperm(n)\n",
    "# 0부터 n-1까지 1씩 늘어나며 값을 랜덤으로 정렬합니다.\n",
    "x = torch.randperm(5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#배치끼리의 행렬곱 = bmm\n",
    "# torch.bmm(batch_matrix1, batch_matrix2)\n",
    "\n",
    "x1=torch.rand(10,3,4)\n",
    "x2=torch.rand(10,4,5)\n",
    "\n",
    "torch.bmm(x1,x2).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) empty , zeros, ones, arrage, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
       "        [0.0000e+00, 1.4013e-45, 0.0000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.empty(size)\n",
    "# 원하는 크기의 빈 텐서를 생성합니다.\n",
    "x = torch.empty(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros(size)\n",
    "# 원하는 크기의 빈 텐서를 생성합니다.\n",
    "x = torch.zeros(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones(size)\n",
    "# 원하는 크기의 1의 값을 가진 텐서를 생성합니다.\n",
    "x = torch.ones(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange(start,end,step=1)\n",
    "# start값부터 end값 전까지 step만큼 더하며 텐서를 생성합니다.\n",
    "x = torch.arange(0,3,step=0.5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4939, 0.4313, 0.7660],\n",
      "        [0.5534, 0.2581, 0.5523]])\n",
      "tensor(0.7660)\n",
      "(tensor([0.7660, 0.5534]), tensor([2, 0]))\n",
      "tensor([2, 0])\n"
     ]
    }
   ],
   "source": [
    "# torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)\n",
    "# tensor의 최대값을 산출합니다.\n",
    "\n",
    "x = torch.rand(2,3)\n",
    "print(x)\n",
    "\n",
    "# 최대값을 출력합니다.\n",
    "print(torch.max(x))\n",
    "\n",
    "# 해당 차원에서 최대값과 그 위치를 출력합니다.\n",
    "print(torch.max(x,1))\n",
    "\n",
    "# 위치를 출력합니다.\n",
    "print(torch.max(x,1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Tensor Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5080e+06,  4.5911e-41,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# torch.empty(size, dtype=)\n",
    "# torch.zeros(size, dtype=)\n",
    "# torch.arange(start,end,dtype=)\n",
    "\n",
    "# torch에서 지원하는 다양한 data type을 옵션으로 지정할 수 있습니다.\n",
    "\n",
    "x = torch.empty(2,3, dtype=torch.float)\n",
    "y = torch.zeros(2,3, dtype = torch.long)\n",
    "z = torch.arange(0,3,step=0.5,dtype=torch.double)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tensor(size or list, dtype = torch.floattensor) \n",
    "# 원하는 텐서를 바로 생성합니다.\n",
    "x = torch.tensor([5.5,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.5080e+06,  4.5911e-41,  1.4013e-45],\n",
      "        [ 0.0000e+00,  1.4013e-45,  0.0000e+00]])\n",
      "tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# torch.FloatTensor(size or list)\n",
    "x = torch.FloatTensor(2,3)\n",
    "print(x)\n",
    "x = torch.FloatTensor([2,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# tensor.type_as(tensor_type)\n",
    "# tensor 형 변환\n",
    "x = x.type_as(torch.IntTensor())\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 12, 3, 3])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tensor.size()\n",
    "\n",
    "x = torch.FloatTensor(10,12,3,3)\n",
    "\n",
    "print(x.size()[:])\n",
    "print(x.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.1433, -0.1459,  0.5400],\n",
      "        [-1.2741, -0.4259, -0.8103],\n",
      "        [-0.4838,  0.9952, -0.5255],\n",
      "        [ 0.9416, -1.2798,  0.9148],\n",
      "        [ 0.6058,  0.2276,  0.8081]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3, dtype=torch.double) #5,3 차원의 새로운 텐서를 생성합니다.\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x,dtype=torch.float) # 같은 size에서 랜덤한 숫자로 채워진 텐서를 생성합니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Math Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]), tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.]]), tensor([[ 2.,  4.,  6.],\n",
       "         [ 8., 10., 12.]]), tensor([[ 2.,  4.,  6.],\n",
       "         [ 8., 10., 12.]]), tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.add()\n",
    "# 텐서의 값끼리 더합니다.\n",
    "\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "add = torch.add(x1, x2)\n",
    "\n",
    "x1,x2,add,x1+x2,x1-x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0562, 0.9970, 0.6525],\n",
       "         [1.5222, 0.7321, 0.4887],\n",
       "         [0.4234, 1.0605, 0.6019],\n",
       "         [1.5088, 0.6406, 0.9157],\n",
       "         [0.0957, 1.1867, 0.7103]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#차원이 다르더라도 안쪽 차원만 같으면 연산이 가능합니다.\n",
    "\n",
    "x = torch.rand(1,5,3)\n",
    "y = torch.rand(5,3)\n",
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9797, 0.6905, 0.5697, 0.3001],\n",
      "        [0.4197, 0.8841, 0.9708, 0.2957],\n",
      "        [0.9136, 0.3232, 0.2683, 0.8903]])\n",
      "tensor([[0.9599, 0.4768, 0.3246, 0.0900],\n",
      "        [0.1762, 0.7817, 0.9424, 0.0874],\n",
      "        [0.8347, 0.1045, 0.0720, 0.7926]]) \n",
      " tensor([[0.9599, 0.4768, 0.3246, 0.0900],\n",
      "        [0.1762, 0.7817, 0.9424, 0.0874],\n",
      "        [0.8347, 0.1045, 0.0720, 0.7926]])\n"
     ]
    }
   ],
   "source": [
    "# torch.pow(input,exponent)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "\n",
    "print(x1)\n",
    "print(torch.pow(x1,2),\"\\n\",x1**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9942, 0.2482, 0.3665, 0.9514],\n",
      "        [0.8012, 0.4907, 0.0162, 0.7903],\n",
      "        [0.1299, 0.6123, 0.2205, 0.1643]])\n",
      "tensor([[2.7025, 1.2817, 1.4427, 2.5894],\n",
      "        [2.2282, 1.6334, 1.0163, 2.2042],\n",
      "        [1.1387, 1.8447, 1.2468, 1.1786]])\n"
     ]
    }
   ],
   "source": [
    "# torch.exp(tensor,out=None)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "\n",
    "print(x1)\n",
    "print(torch.exp(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6287, 0.3815, 0.7263, 0.6222],\n",
      "        [0.5106, 0.5622, 0.8236, 0.4261],\n",
      "        [0.7156, 0.4511, 0.5921, 0.2744]])\n",
      "tensor([[-0.4642, -0.9636, -0.3198, -0.4746],\n",
      "        [-0.6721, -0.5758, -0.1941, -0.8531],\n",
      "        [-0.3347, -0.7960, -0.5240, -1.2931]])\n"
     ]
    }
   ],
   "source": [
    "# torch.log(input,out=None)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "\n",
    "print(x1)\n",
    "print(torch.log(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4853, 0.4143, 0.2360, 0.4805, 0.7299],\n",
       "        [0.1824, 0.1489, 0.0255, 0.1774, 0.0389],\n",
       "        [0.5269, 0.2769, 0.1885, 0.3560, 0.9062]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# torch.mm(matrix1, matrix2)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "x2 = torch.rand(4,5)\n",
    "\n",
    "torch.mm(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.bmm(batch_matrix1, batch_matrix2)\n",
    "\n",
    "x1 = torch.rand(10,3,4)\n",
    "x2 = torch.rand(10,4,5)\n",
    "\n",
    "torch.bmm(x1,x2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.dot(tensor1, tensor2)\n",
    "\n",
    "torch.dot(torch.tensor([2,3]), torch.tensor([2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 4]), torch.Size([10, 4, 3]), torch.Size([10, 4, 3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.t(matrix)\n",
    "# tranpose\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "print(x1.size(), x1.t().size())\n",
    "\n",
    "# torch.transpose(input,dim0,dim1)\n",
    "\n",
    "x1 = torch.rand(10,3,4)\n",
    "x1.size(), torch.transpose(x1,1,2).size(), x1.transpose(1,2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([16]) tensor([ 0.2608, -0.0604,  0.6726, -2.3146, -0.8927, -0.9933, -1.1368, -0.5905,\n",
      "        -1.5724,  0.0433,  1.4543, -0.5445, -1.3004,  0.3925, -0.2250, -0.2531])\n",
      "torch.Size([2, 8]) tensor([[ 0.2608, -0.0604,  0.6726, -2.3146, -0.8927, -0.9933, -1.1368, -0.5905],\n",
      "        [-1.5724,  0.0433,  1.4543, -0.5445, -1.3004,  0.3925, -0.2250, -0.2531]])\n"
     ]
    }
   ],
   "source": [
    "#viw()  = 맨마지막에 일자로 만들어준다.\n",
    "\n",
    "\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8) # -1의 경우 다른 차원들로 유추합니다. 이 경우에는 2로 유추합니다.\n",
    "print(x.size())\n",
    "print(y.size(),y)\n",
    "print(z.size(),z)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, Slicing, Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7734, 0.5874, 0.1098],\n",
      "        [0.4298, 0.6976, 0.5652],\n",
      "        [0.9444, 0.4052, 0.8905],\n",
      "        [0.4092, 0.8520, 0.0903]]) \n",
      " tensor([[0.7734, 0.5874, 0.1098],\n",
      "        [0.4092, 0.8520, 0.0903]])\n"
     ]
    }
   ],
   "source": [
    "# Indexing\n",
    "# tensor.index_select(input,dim,index)\n",
    "\n",
    "x = torch.rand(4,3)\n",
    "out = torch.index_select(x,0,torch.LongTensor([0,3]))\n",
    "# index는 꼭 Longtensor로 입력해야 합니다.\n",
    "\n",
    "print(x, \"\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[ 1.,  2.,  3.,  7.,  8.,  9.],\n",
      "        [ 4.,  5.,  6., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Joining\n",
    "# torch.cat(seq, dim=0)\n",
    "# dim을 기준으로 tensor를 합칩니다.\n",
    "# dim = 0은 행, dim = 1은 열 기준입니다.\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "y = torch.FloatTensor([[7,8,9],\n",
    "                       [10,11,12]])\n",
    "z1 = torch.cat([x,y],dim = 0)\n",
    "z2 = torch.cat([x,y],dim = 1)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[ 1.],\n",
      "        [ 4.],\n",
      "        [ 7.],\n",
      "        [10.]])\n",
      "tensor([[ 2.],\n",
      "        [ 5.],\n",
      "        [ 8.],\n",
      "        [11.]])\n",
      "tensor([[ 3.],\n",
      "        [ 6.],\n",
      "        [ 9.],\n",
      "        [12.]])\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "# torch.chunk(tensor, chunks, dim=0)\n",
    "# tensor를 chunk 단위로 쪼갭니다.\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "y = torch.FloatTensor([[7,8,9],\n",
    "                       [10,11,12]])\n",
    "z1 = torch.cat([x,y],dim = 0)\n",
    "\n",
    "x_1, x_2 = torch.chunk(z1,2,dim=0)\n",
    "y_1, y_2, y_3 = torch.chunk(z1,3,dim=1)\n",
    "\n",
    "print(z1)\n",
    "print(x_1)\n",
    "print(x_2)\n",
    "print(y_1)\n",
    "print(y_2)\n",
    "print(y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 3, 1, 4]), torch.Size([10, 3, 4]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeezing\n",
    "\n",
    "# torch.squeez(input, dim=None)\n",
    "# 1짜리 차원을 줄입니다.\n",
    "\n",
    "x1 = torch.FloatTensor(10,1,3,1,4)\n",
    "x2 = torch.squeeze(x1)\n",
    "\n",
    "x1.size(), x2.size()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
