{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXHZY9eP_32G"
   },
   "source": [
    "## 0. Google Colab 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amsQv2HJ_80D"
   },
   "source": [
    "- Colab 사용법은 [변성윤 선배님의 블로그](https://zzsza.github.io/data/2018/08/30/google-colab/)를 참고해주세요.\n",
    "- 공식 홈페이지 [document](https://colab.research.google.com/notebooks/welcome.ipynb)도 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGXQFcG1B3nn"
   },
   "source": [
    "## 1. Pytorch 연습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcDozxxCB6N2"
   },
   "source": [
    "- 먼저 [Pytorch-A-to-Z](https://github.com/shwksl101/Pytorch-A-to-Z) 에서 1~3까지 필사해서 밑에다가 써주세요.\n",
    "- 질문은 주석으로 달아놓고 코드 리뷰 시간에 이야기해보면 좋을 것 같습니다.\n",
    "- 오류가 있을 수 있으니 이상한 부분이 있으면 질문 부탁드립니다.\n",
    "\n",
    "--> 너무 길어서 따로 \n",
    "\n",
    "(Optional)\n",
    "- 다음은 개인적으로 최윤제님의 [Pytorch tutorial](https://github.com/yunjey/pytorch-tutorial)을 추천드립니다.\n",
    "- GPU 사용법은 다음 [링크](https://pytorch.org/docs/stable/notes/cuda.html)를 참고해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basics \n",
    " 1. Basic autograd example 1            \n",
    " 2. Basic autograd example 2            \n",
    " 3. Loading data from numpy               \n",
    " 4. Input pipline                         \n",
    " 5. Input pipline for custom dataset      \n",
    " 6. Pretrained model                      \n",
    " 7. Save and load model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3f4v8Sc9Ywf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "w:  Parameter containing:\n",
      "tensor([[ 0.2127, -0.4811, -0.4264],\n",
      "        [ 0.4012, -0.5390, -0.0575]], requires_grad=True)\n",
      "b:  Parameter containing:\n",
      "tensor([-0.0161,  0.4302], requires_grad=True)\n",
      "loss:  1.2844661474227905\n",
      "dL/dw:  tensor([[-0.1021, -0.7810, -0.3798],\n",
      "        [-0.1342, -0.6784, -0.3257]])\n",
      "dL/db:  tensor([0.3933, 0.6867])\n",
      "loss after 1 step optimization:  1.2648507356643677\n",
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n",
      "6\n",
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torch. nn as nn\n",
    "import numpy as np \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#                     1. Basic autograd example 1     \n",
    "   # Create tensors.     \n",
    "x= torch.tensor(1., requires_grad= True)\n",
    "w= torch.tensor(2., requires_grad=True)\n",
    "b= torch.tensor (3., requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y=w*x+b  # y = 2 * x + 3\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad) #2\n",
    "print(w.grad) #1\n",
    "print(b.grad) #1\n",
    "\n",
    "#                    2. Basic autograd example 2   \n",
    "\n",
    "# Create tensors of shape (10,3) and (10,2)\n",
    "x=torch.randn(10,3)\n",
    "y=torch.randn(10,2)\n",
    "\n",
    "linear= nn.Linear(3,2)\n",
    "print('w: ',linear.weight)\n",
    "print('b: ',linear.bias)\n",
    "\n",
    "criterion= nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(linear.parameters(),lr=0.01)\n",
    "\n",
    "pred = linear(x)\n",
    "loss=criterion(pred,y)\n",
    "print('loss: ',loss.item())\n",
    "\n",
    "loss.backward()\n",
    "print('dL/dw: ',linear.weight.grad)\n",
    "print('dL/db: ',linear.bias.grad)\n",
    "\n",
    "optimizer.step()\n",
    "\n",
    "pred=linear(x)\n",
    "loss=criterion(pred,y)\n",
    "print('loss after 1 step optimization: ',loss.item())\n",
    "              \n",
    "#                     3. Loading data from numpy   \n",
    "\n",
    "x=np.array([[1,2],[3,4]])\n",
    "y=torch.from_numpy(x)\n",
    "z=y.numpy()\n",
    "z\n",
    "#                         4. Input pipline  \n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True,\n",
    "                                            transform=transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print(image.size())\n",
    "print(label)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                         batch_size=64,\n",
    "                                         shuffle=True)\n",
    "data_iter=iter(train_loader)\n",
    "images,lables=data_iter.next()\n",
    "for images,labels in train_loader:\n",
    "    pass\n",
    "\n",
    "\n",
    "#                5. Input pipline for custom dataset  \n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file paths or a list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0 \n",
    "\n",
    "# You can then use the prebuilt data loader. \n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "#                        6. Pretrained model   \n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad= False\n",
    "resnet.fc= nn.Linear(resnet.fc.in_features,100)\n",
    "\n",
    "images= torch.randn(64,3,224,224)\n",
    "outputs=resnet(images)\n",
    "print(outputs.size())\n",
    "\n",
    "#                      7. Save and load the model\n",
    "\n",
    "torch.save(resnet,'model.ckpt')\n",
    "model=torch.load('model.ckpt')\n",
    "\n",
    "torch.save(resnet.state_dict(),'params.ckpt')\n",
    "resnet.load_state_dict(torch.load('params.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWZuY8jj7e5s"
   },
   "source": [
    "## 2. Regression 연습하기\n",
    "\n",
    "- [house price](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)에서 train data를 받아주세요\n",
    "- train/test set을 7:3 비율로 나누세요\n",
    "- Pytorch 라이브러리를 이용해 최대한의 성능을 내보세요\n",
    "- Metric은 RMSE를 사용해 계산해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9KmHO-NkwHLX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>599</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12984</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>217500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8544</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>124900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1337</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>87.0</td>\n",
       "      <td>9246</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>312</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "598    599          20       RL         80.0    12984   Pave   NaN      Reg   \n",
       "31      32          20       RL          NaN     8544   Pave   NaN      IR1   \n",
       "59      60          20       RL         60.0     7200   Pave   NaN      Reg   \n",
       "1336  1337          90       RL         87.0     9246   Pave   NaN      IR1   \n",
       "311    312          20       RL         50.0     8000   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "598          Bnk    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "31           Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "59           Bnk    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1336         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "311          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "598       3   2006        WD         Normal     217500  \n",
       "31        6   2008        WD         Normal     149350  \n",
       "59        1   2008        WD         Normal     124900  \n",
       "1336     11   2008        WD         Normal     135000  \n",
       "311       5   2009        WD         Normal     132000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_test = pd.read_csv('./house_price_data/train.csv')\n",
    "train ,test = train_test_split(train_test,test_size=0.3) \n",
    "\n",
    "\n",
    "train.head()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyunju\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n",
      "C:\\Users\\hyunju\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100],  train loss (rmse) [ 0.5261] valid loss (rmse) [0.5146]\n",
      "Epoch [20/100],  train loss (rmse) [ 0.1743] valid loss (rmse) [0.1695]\n",
      "Epoch [30/100],  train loss (rmse) [ 0.1649] valid loss (rmse) [0.1721]\n",
      "Epoch [40/100],  train loss (rmse) [ 0.1558] valid loss (rmse) [0.1596]\n",
      "Epoch [50/100],  train loss (rmse) [ 0.1473] valid loss (rmse) [0.1513]\n",
      "Epoch [60/100],  train loss (rmse) [ 0.1429] valid loss (rmse) [0.1489]\n",
      "Epoch [70/100],  train loss (rmse) [ 0.1389] valid loss (rmse) [0.1452]\n",
      "Epoch [80/100],  train loss (rmse) [ 0.1354] valid loss (rmse) [0.1426]\n",
      "Epoch [90/100],  train loss (rmse) [ 0.1334] valid loss (rmse) [0.1431]\n",
      "Epoch [100/100],  train loss (rmse) [ 0.1321] valid loss (rmse) [0.1440]\n",
      "Finish !\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_rmse_log(model, feature, label, use_gpu):\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    if use_gpu:\n",
    "        feature = feature.cuda()\n",
    "        label = label.cuda()\n",
    "    feature = Variable(feature, volatile=True)\n",
    "    label = Variable(label, volatile=True)\n",
    "    pred = model(feature)\n",
    "    clipped_pred = torch.clamp(pred, 1, float('inf'))\n",
    "    rmse = torch.sqrt(mse_loss(clipped_pred.log(), label.log()))\n",
    "    return rmse.item()\n",
    "  \n",
    "  \n",
    "all_features = pd.concat((train.loc[:, 'MSSubClass':'SaleCondition'],\n",
    "                          test.loc[:, 'MSSubClass':'SaleCondition']))\n",
    "\n",
    "\n",
    "numeric_feats = all_features.dtypes[all_features.dtypes != \"object\"].index \n",
    "all_features[numeric_feats] = all_features[numeric_feats].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "             \n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)   \n",
    "all_features = all_features.fillna(all_features.mean())\n",
    "\n",
    "\n",
    "num_train = train.shape[0]\n",
    "\n",
    "train_features = all_features[:num_train].values.astype(np.float32)\n",
    "test_features = all_features[num_train:].values.astype(np.float32)\n",
    "\n",
    "train_labels = train.SalePrice.values[:, None].astype(np.float32)\n",
    "test_labels = test.SalePrice.values[:, None].astype(np.float32)\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(331, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(200, 150),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(150, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(50, 20),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(20, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, 1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "use_gpu = False\n",
    "lr = 0.0002\n",
    "weight_decay = 10\n",
    "\n",
    "if use_gpu:\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "else:\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "train_features = torch.from_numpy(train_features).float()\n",
    "train_labels = torch.from_numpy(train_labels).float()\n",
    "test_features = torch.from_numpy(test_features).float()\n",
    "test_labels = torch.from_numpy(test_labels).float()\n",
    "\n",
    "def get_data(x, y, batch_size, shuffle):\n",
    "    dataset = TensorDataset(x, y)\n",
    "    return DataLoader(dataset, batch_size, shuffle=shuffle, num_workers=4)\n",
    "\n",
    "def train_model(model, x_train, y_train, x_valid, y_valid, epochs, lr, weight_decay):\n",
    "    metric_log = dict()\n",
    "    metric_log['train_loss'] = list()\n",
    "    if x_valid is not None:\n",
    "        metric_log['valid_loss'] = list()\n",
    "    \n",
    "    train_data = get_data(x_train, y_train, batch_size, True)\n",
    "    if x_valid is not None:\n",
    "        valid_data = get_data(x_valid, y_valid, batch_size, False)\n",
    "    else:\n",
    "        valid_data = None\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        for data in train_data:\n",
    "            x, y = data\n",
    "            if use_gpu:\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            x = Variable(x)\n",
    "            y = Variable(y)\n",
    "\n",
    "            out = model(x)\n",
    "\n",
    "            loss = criterion(out, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss\n",
    "           \n",
    "        \n",
    "        metric_log['train_loss'].append(get_rmse_log(model, x_train, y_train, use_gpu))\n",
    "        metric_log['valid_loss'].append(get_rmse_log(model, x_valid, y_valid, use_gpu))\n",
    "\n",
    "        if (e + 1) % 10 == 0:\n",
    "            print('Epoch [%d/%d],  train loss (rmse) [ %.4f] valid loss (rmse) [%.4f]'\n",
    "                  % (e+1, epochs,  metric_log['train_loss'][-1],metric_log['valid_loss'][-1]))\n",
    "\n",
    "model = get_model()\n",
    "train_model(model, train_features, train_labels, test_features, test_labels, epochs, lr, weight_decay)\n",
    "print('Finish !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4kokxhYQ84Hu"
   },
   "source": [
    "## 3. Classification 연습하기\n",
    "- [mushroom](https://www.kaggle.com/uciml/mushroom-classification)에서 data를 받아주세요\n",
    "- train/test set을 7:3 비율로 나누세요\n",
    "- Pytorch 라이브러리를 이용해 최대한의 성능을 내보세요\n",
    "- Metric은 accuracy을 사용해 계산해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0UkMax_wJZ_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  ...  stalk-surface-below-ring  \\\n",
       "0             0          1           4  ...                         2   \n",
       "1             0          0           4  ...                         2   \n",
       "2             0          0           5  ...                         2   \n",
       "3             0          1           5  ...                         2   \n",
       "4             1          0           4  ...                         2   \n",
       "\n",
       "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
       "0                       7                       7          0           2   \n",
       "1                       7                       7          0           2   \n",
       "2                       7                       7          0           2   \n",
       "3                       7                       7          0           2   \n",
       "4                       7                       7          0           2   \n",
       "\n",
       "   ring-number  ring-type  spore-print-color  population  habitat  \n",
       "0            1          4                  2           3        5  \n",
       "1            1          4                  3           2        1  \n",
       "2            1          4                  3           2        3  \n",
       "3            1          4                  2           3        5  \n",
       "4            1          0                  3           0        1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as f\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "mushroom_data = pd.read_csv('./mushroom_data/mushrooms.csv')\n",
    "# mushroom_data = prepare_dataset(mushroom_data)\n",
    "new_dataset = mushroom_data\n",
    "ch = list(mushroom_data.columns.values)\n",
    "encoder = LabelEncoder()\n",
    "for i in ch:   \n",
    "    column = new_dataset[i]\n",
    "    column = encoder.fit_transform(column)\n",
    "    new_dataset[i]=column\n",
    "new_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2 4 ... 2 3 5]\n",
      " [5 2 9 ... 3 2 1]\n",
      " [0 2 8 ... 3 2 3]\n",
      " ...\n",
      " [2 2 4 ... 0 1 2]\n",
      " [3 3 4 ... 7 4 2]\n",
      " [5 2 4 ... 4 1 2]]\n",
      "[1 0 0 ... 0 1 0]\n",
      "(5686, 22)\n",
      "(5686,)\n",
      "(2438, 22)\n",
      "(2438,)\n"
     ]
    }
   ],
   "source": [
    "def labels_vs_features(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    y = dataset['class']\n",
    "    ch = list(dataset.columns.values)\n",
    "    for i in ch:\n",
    "        if i == 'class':\n",
    "            continue\n",
    "        else:\n",
    "            X.append(dataset[i])\n",
    "    return np.array(X).T, np.array(y)\n",
    "\n",
    "X, y = labels_vs_features(new_dataset)\n",
    "print(X)\n",
    "print(y)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y,test_size=0.3)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyunju\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100]  Epoch accuracy: 0.8714285714285713  loss: 0.3602561354637146\n",
      "Epoch [20/100]  Epoch accuracy: 0.8942857142857142  loss: 0.29790326952934265\n",
      "Epoch [30/100]  Epoch accuracy: 0.9051785714285714  loss: 0.2625884413719177\n",
      "Epoch [40/100]  Epoch accuracy: 0.915357142857143  loss: 0.23491324484348297\n",
      "Epoch [50/100]  Epoch accuracy: 0.9232142857142857  loss: 0.20985375344753265\n",
      "Epoch [60/100]  Epoch accuracy: 0.9323214285714286  loss: 0.18666216731071472\n",
      "Epoch [70/100]  Epoch accuracy: 0.9412499999999999  loss: 0.1666925698518753\n",
      "Epoch [80/100]  Epoch accuracy: 0.9498214285714285  loss: 0.14951398968696594\n",
      "Epoch [90/100]  Epoch accuracy: 0.9594642857142858  loss: 0.1348707377910614\n",
      "Epoch [100/100]  Epoch accuracy: 0.9648214285714285  loss: 0.12225589901208878\n",
      "0.9670833333333334\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1, 1)\n",
    "def accuracy(preds, y_true):\n",
    "    correct = 0\n",
    "    assert len(preds) == len(y_true)\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] >= 0.5:\n",
    "            if y_true[i] == 1:\n",
    "                correct += 1\n",
    "        else:\n",
    "            if y_true[i] == 0:\n",
    "                correct += 1\n",
    "    \n",
    "    return correct / len(preds)\n",
    "\n",
    "\n",
    "class FullyConnectedNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_of_features):\n",
    "        super(FullyConnectedNN, self).__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(num_of_features, 100)\n",
    "        self.fc_2 =  nn.Linear(100, 1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        l1 = f.relu(self.fc_1(X))\n",
    "        output = f.sigmoid(self.fc_2(l1))\n",
    "        return output\n",
    "    \n",
    "features = 22\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 0.005\n",
    "\n",
    "net = FullyConnectedNN(features)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    epoch_accuracy = []\n",
    "    epoch_loss = []\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "        starting_id = i * batch_size\n",
    "        ending_id = starting_id + batch_size\n",
    "        \n",
    "        X_batch = Variable(torch.from_numpy(np.float32(X_train[starting_id:ending_id])))\n",
    "        y_batch = Variable(torch.from_numpy(np.float32(y_train[starting_id:ending_id])))\n",
    "        \n",
    "        optimizer.zero_grad() #reset net to 0 grads\n",
    "        predictions = net(X_batch)\n",
    "        epoch_accuracy.append(accuracy(predictions.cpu().data.numpy(), y_train[starting_id:ending_id]))\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        epoch_loss.append(loss.cpu().data.numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch [{}/{}]'.format(epoch+1, epochs), \n",
    "              ' Epoch accuracy: {}'.format(np.mean(epoch_accuracy)), \n",
    "              ' loss: {}'.format(np.mean(epoch_loss)))\n",
    " \n",
    " #Testring\n",
    "\n",
    "test_accuracy = []\n",
    "\n",
    "for i in range(len(X_test) // batch_size):\n",
    "    starting_id = i * batch_size\n",
    "    ending_id = starting_id + batch_size\n",
    "\n",
    "    X_batch = Variable(torch.from_numpy(np.float32(X_test[starting_id:ending_id])))\n",
    "    y_batch = Variable(torch.from_numpy(np.float32(y_test[starting_id:ending_id])))\n",
    "\n",
    "    predictions = net(X_batch)\n",
    "\n",
    "    test_accuracy.append(accuracy(predictions.cpu().data.numpy(), y_test[starting_id:ending_id]))\n",
    "                         \n",
    "print(np.mean(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "분석 12기 6주차 과제.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
