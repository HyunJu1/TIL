{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eb42ca6e4af3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# torch.rand(size)\n",
    "# 0~1 사이의 연속균등분포에서 값을 뽑아 5x3 텐서를 생성합니다. ~U(0,1)\n",
    "x = torch.rand(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x1=torch.rand(3,4)\n",
    "x2=torch.rand(4,5)\n",
    "torch.mm(x1,x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#배치끼리의 행렬곱 = bmm\n",
    "# torch.bmm(batch_matrix1, batch_matrix2)\n",
    "\n",
    "x1=torch.rand(10,3,4)\n",
    "x2=torch.rand(10,4,5)\n",
    "\n",
    "torch.bmm(x1,x2).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viw()  = 맨마지막에 일자로 만들어준다.\n",
    "\n",
    "\n",
    "#squeeze ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "batch_size=32\n",
    "learning_rate=0.01\n",
    "num_epochs=5\n",
    "\n",
    "train_dataset=datasets.MNIST(root='./data',train =True, \n",
    "                             transform = transforms.ToTensor(), download=True)\n",
    "test_dataset=datasets.MNIST(root='./data',train =False, \n",
    "                             transform = transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle = True)\n",
    "test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-837d19349b30>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-837d19349b30>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    def __init__(self,num_classes=10):\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        super(Neuralnetwork,self).__init__()\n",
    "        self.layer1=nn.Linear(28*28,100)\n",
    "        self.layer2=nn.Linear(100,200)\n",
    "        self.layer3=nn.Linear(200,num_classes)\n",
    "        \n",
    "        def forward(self,x):\n",
    "            out=x.view(x.size(0),-1)\n",
    "            out=self.layer1(out)\n",
    "            out=self.layer2(out)\n",
    "            out=self.layer3(out)\n",
    "            return out\n",
    "#MODEL\n",
    "model=Neuralnetwork()\n",
    "#LOSS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#OPTIMIZER\n",
    "optimiizer = optim.SGD(model.parameters(),lr=learning_rate)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "su"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
